{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "layer_num = 4\n",
    "# config = \"{'\n",
    "# vocab_size': 128256, \n",
    "# 'max_position_embeddings': 8192, \n",
    "# 'hidden_size': 4096, \n",
    "# 'intermediate_size': 14336, \n",
    "# 'num_hidden_layers': 32, \n",
    "# 'num_attention_heads': 32, \n",
    "# 'num_key_value_heads': 8, \n",
    "# 'hidden_act': 'silu', \n",
    "# 'initializer_range': 0.02, \n",
    "# 'rms_norm_eps': 1e-05, \n",
    "# 'pretraining_tp': 1, \n",
    "# 'use_cache': True, \n",
    "# 'rope_theta': 500000.0, \n",
    "# 'rope_scaling': None, \n",
    "# 'attention_bias': False, \n",
    "# 'attention_dropout': 0.0, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 125, 32])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repeatkv(x):\n",
    "    # [4,8,125,32]->[4,8,4,125,32]->[4,32,125,32]\n",
    "    shape = list(x.shape)\n",
    "    shape[1] *= 4\n",
    "    return x.unsqueeze(2).repeat(1,1,4,1,1).reshape(shape)\n",
    "repeatkv(torch.randn(4,8,125,32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 32, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 16, 32]), torch.Size([1, 16, 32]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 没看懂啊！！！\n",
    "def llama_rotary_pos_embed(lens):\n",
    "    inv_freq = torch.arange(0,32,2) / 32\n",
    "    inv_freq = 1.0 / (50_0000.0 ** inv_freq)\n",
    "    inv_freq = inv_freq.reshape(1, 16, 1)\n",
    "\n",
    "    position_ids = torch.arange(lens).reshape(1,1,-1).float()\n",
    "    freqs = inv_freq.matmul(position_ids).transpose(1,2)\n",
    "    emb = torch.cat((freqs, freqs), 2)\n",
    "\n",
    "    return emb.cos(), emb.sin()\n",
    "cos, sin = llama_rotary_pos_embed(16)\n",
    "cos.shape, sin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 125, 32])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_RoPE(x, cos, sin):\n",
    "    def rotate_half(x):\n",
    "        left = x[...,:16]\n",
    "        right = x[...,16:]\n",
    "        return torch.cat((right, left), -1)\n",
    "    \n",
    "    cos = cos.unsqueeze(1)\n",
    "    sin = sin.unsqueeze(1)\n",
    "\n",
    "    x = (rotate_half(x)*sin) + (x*cos)\n",
    "    return x\n",
    "\n",
    "\n",
    "input = {\n",
    "    'x': torch.randn(4, 32, 125, 32),\n",
    "    'sin': torch.randn(1, 125, 32),\n",
    "    'cos': torch.randn(1, 125, 32)\n",
    "}\n",
    "apply_RoPE(**input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00, -1.0000e+15, -1.0000e+15, -1.0000e+15, -1.0000e+15],\n",
       "          [ 0.0000e+00,  0.0000e+00, -1.0000e+15, -1.0000e+15, -1.0000e+15],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+15, -1.0000e+15],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+15],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mask(attention_mask):\n",
    "    # attention_mask -> [4, 125]\n",
    "    b, lens = attention_mask.shape\n",
    "\n",
    "    min_value = -1e15\n",
    "    casual_mask = torch.full((lens, lens), min_value).triu(diagonal=1) # [125,125]\n",
    "    casual_mask = casual_mask.reshape(1, 1, lens, lens).repeat(b, 1, 1, 1)\n",
    "    casual_mask = casual_mask.to(attention_mask.device)\n",
    "\n",
    "    mask = attention_mask.reshape(b, 1, 1, lens) == 0\n",
    "    casual_mask = casual_mask.masked_fill(mask, min_value)\n",
    "    return casual_mask\n",
    "get_mask(torch.ones(1, 5).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 125, 1024])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LlamaRMSNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-6):\n",
    "        super().__init__()\n",
    "        # [1, hidden_size]\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        print(self.weight.shape)\n",
    "        self.eps = eps\n",
    "    # x.shape = [4,125,1024]\n",
    "    def forward(self, x):\n",
    "        var = x.pow(2).mean(-1, keepdim=True)\n",
    "        x = x * (var + self.eps).rsqrt()\n",
    "        return self.weight * x\n",
    "\n",
    "LlamaRMSNorm(1024)(torch.randn(4, 125, 1024)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP SiLU activation function , highlight the important info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 125, 1024])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LlamaMLP(torch.nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.up_proj = nn.Linear(hidden_size, 4*hidden_size, bias=False)\n",
    "        self.gate_proj = nn.Linear(hidden_size, 4 * hidden_size, bias=False)\n",
    "        self.down_proj = nn.Linear(4*hidden_size, hidden_size, bias=False)\n",
    "        self.act_fn = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        left = self.act_fn(self.gate_proj(x))\n",
    "        right = self.up_proj(x)\n",
    "        return self.down_proj(left * right)\n",
    "\n",
    "LlamaMLP(1024)(torch.randn(4, 125, 1024)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 125, 1024])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LlamaAttention(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.q_proj = nn.Linear(1024, 1024, bias=False)\n",
    "        self.k_proj = nn.Linear(1024, 256, bias=False) # 为什么是256，kv-cache query分为4组 每组共享kv权重，共8组\n",
    "        self.v_proj = nn.Linear(1024, 256, bias=False)\n",
    "        self.o_proj = nn.Linear(1024, 1024, bias=False)\n",
    "\n",
    "    # hidden_states -> [4, 125, 1024]\n",
    "    # attention_mask -> [4, 125]\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        b, l, _ = hidden_states.shape\n",
    "\n",
    "        q = self.q_proj(hidden_states).reshape(b, l, 32, 32).transpose(1, 2)\n",
    "        k = self.k_proj(hidden_states).reshape(b, l, 8, 32).transpose(1, 2)\n",
    "        v = self.v_proj(hidden_states).reshape(b, l, 8, 32).transpose(1, 2)\n",
    "        \n",
    "        # 加入位置编码\n",
    "        cos, sin = llama_rotary_pos_embed(l)\n",
    "        cos, sin = cos.to(hidden_states.device), sin.to(hidden_states.device)\n",
    "        q = apply_RoPE(q, cos, sin)\n",
    "        k = apply_RoPE(k, cos, sin)\n",
    "        \n",
    "        # 复制对其尺寸 # [b, 32, 125, 32]\n",
    "        k = repeatkv(k) \n",
    "        v = repeatkv(v)\n",
    "        # shape [4,32,125,125]\n",
    "        attn = q.matmul(k.transpose(-2,-1)) / math.sqrt(32) # 除以sqrt（dk） 防止梯度爆炸\n",
    "\n",
    "        # 加入attn_mask[4,1,125,125]\n",
    "        attention_mask = get_mask(attention_mask)\n",
    "        attn = (attn + attention_mask).softmax(3) # 为什么要做softmax(3)\n",
    "\n",
    "        attn = attn.matmul(v) # [4,32,125,32]\n",
    "        attn = attn.transpose(1,2).reshape(b,l,-1)\n",
    "        attn = self.o_proj(attn)\n",
    "\n",
    "        return attn\n",
    "    \n",
    "input = {\n",
    "    'hidden_states' : torch.randn(4, 125, 1024),\n",
    "    'attention_mask' : torch.rand(4, 125)\n",
    "}\n",
    "LlamaAttention()(**input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def forward(self, x):\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def forward(self, x):\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
